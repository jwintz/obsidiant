#!/usr/bin/env node

import { Command } from 'commander';
import * as fs from 'fs';
import * as path from 'path';
import * as yauzl from 'yauzl';
import { promisify } from 'util';
import * as xml2js from 'xml2js';

const program = new Command();

// Define the CLI interface
program
    .name('obsidiant')
    .description('CLI tool for processing EPUB files')
    .version('0.0.1');

// Add the main command with --mode epub option
program
    .argument('<input>', 'Input EPUB file path')
    .option('-m, --mode <mode>', 'Processing mode', 'epub')
    .option('-o, --output <path>', 'Output directory path', './Books')
    .action(async (input: string, options: { mode: string; output: string; }) => {
        await processEpubFile(input, options.mode, options.output);
    });

/**
 * Process an EPUB file based on the specified mode
 */
async function processEpubFile(inputPath: string, mode: string, outputPath: string): Promise<void> {
    console.log(`Processing file: ${inputPath}`);
    console.log(`Mode: ${mode}`);
    console.log(`Output directory: ${outputPath}`);

    // Validate input file exists
    if (!fs.existsSync(inputPath)) {
        console.error(`Error: File '${inputPath}' does not exist.`);
        process.exit(1);
    }

    // Validate file extension
    const fileExtension = path.extname(inputPath).toLowerCase();
    if (fileExtension !== '.epub') {
        console.error(`Error: Expected .epub file, but got '${fileExtension}' file.`);
        process.exit(1);
    }

    // Validate mode
    if (mode !== 'epub') {
        console.error(`Error: Unsupported mode '${mode}'. Currently only 'epub' mode is supported.`);
        process.exit(1);
    }

    try {
        console.log('üîÑ Starting EPUB processing...');

        // Process EPUB content
        await processEpubContent(inputPath, outputPath);

        console.log('‚úÖ EPUB processing completed successfully!');
    } catch (error) {
        console.error('‚ùå Error processing EPUB file:', error instanceof Error ? error.message : String(error));
        process.exit(1);
    }
}

/**
 * Core EPUB processing logic
 */
async function processEpubContent(filePath: string, outputPath: string): Promise<void> {
    console.log(`üìñ Analyzing EPUB structure: ${path.basename(filePath)}`);

    // Get file stats
    const stats = fs.statSync(filePath);
    console.log(`üìä File size: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
    console.log(`üìÖ Last modified: ${stats.mtime.toLocaleDateString()}`);

    // Extract EPUB archive
    console.log('üì¶ Extracting EPUB archive...');
    const extractedContent = await extractEpubArchive(filePath);

    // Parse EPUB metadata and structure
    console.log('üìã Parsing EPUB metadata...');
    const epubMetadata = await parseEpubMetadata(extractedContent.entries);
    console.log(`üìñ Book: ${epubMetadata.title || 'Unknown Title'}`);
    console.log(`üë§ Author: ${epubMetadata.creator || 'Unknown Author'}`);
    console.log(`üìÑ OPF Location: ${epubMetadata.opfPath}`);

    // Classify content structure
    console.log('üìö Analyzing content structure...');
    const contentClassification = await classifyEpubContent(epubMetadata.spine, extractedContent.entries);


    // Log detailed classification results
    console.log('\nüîç Content Classification Results:');
    console.log(JSON.stringify(contentClassification, null, 2));

    console.log(`  üìÑ Front matter: ${contentClassification.frontMatter.length} items`);
    if (contentClassification.prologue) {
        console.log(`  üìñ Prologue: "${contentClassification.prologue.title || contentClassification.prologue.href}"`);
    }
    console.log(`  üìö Chapters: ${contentClassification.chapters.length} items`);
    if (contentClassification.epilogue) {
        console.log(`  üìñ Epilogue: "${contentClassification.epilogue.title || contentClassification.epilogue.href}"`);
    }
    console.log(`  üìÑ Back matter: ${contentClassification.backMatter.length} items`);

    // Generate Obsidian output
    console.log('üìù Generating Obsidian output...');
    await generateObsidianOutput(extractedContent.entries, epubMetadata, outputPath, contentClassification);

    // /////////////////////////////////////////////////////////////////////////////
    // TODO: This is temporary
    // /////////////////////////////////////////////////////////////////////////////

    // Create extraction directory
    const extractDir = path.join(path.dirname(filePath), `${path.basename(filePath, '.epub')}_extracted`);
    console.log(`üíæ Writing extracted files to: ${extractDir}`);

    // Write extracted files to disk
    await writeExtractedFiles(extractedContent.entries, extractDir);

    console.log(`‚úÖ Extracted ${extractedContent.entries.length} files from EPUB`);
    console.log(`üìÅ Files available at: ${extractDir}`);

    // /////////////////////////////////////////////////////////////////////////////

    console.log('üîç EPUB content analysis completed');
}

/**
 * Extract EPUB archive (ZIP file) and return its contents
 */
async function extractEpubArchive(filePath: string): Promise<{ entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>; }> {
    return new Promise((resolve, reject) => {
        const entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }> = [];

        yauzl.open(filePath, { lazyEntries: true }, (err, zipfile) => {
            if (err) {
                reject(new Error(`Failed to open EPUB file: ${err.message}`));
                return;
            }

            if (!zipfile) {
                reject(new Error('Failed to open ZIP file'));
                return;
            }

            zipfile.readEntry();

            zipfile.on('entry', (entry) => {
                const fileName = entry.fileName;
                console.log(`  üìÑ Found: ${fileName}`);

                if (/\/$/.test(fileName)) {
                    // Directory entry
                    entries.push({ fileName, content: Buffer.alloc(0), isDirectory: true });
                    zipfile.readEntry();
                } else {
                    // File entry
                    zipfile.openReadStream(entry, (err, readStream) => {
                        if (err) {
                            reject(new Error(`Failed to read entry ${fileName}: ${err.message}`));
                            return;
                        }

                        if (!readStream) {
                            reject(new Error(`Failed to open read stream for ${fileName}`));
                            return;
                        }

                        const chunks: Buffer[] = [];
                        readStream.on('data', (chunk) => {
                            chunks.push(chunk);
                        });

                        readStream.on('end', () => {
                            const content = Buffer.concat(chunks);
                            entries.push({ fileName, content, isDirectory: false });
                            zipfile.readEntry();
                        });

                        readStream.on('error', (err) => {
                            reject(new Error(`Error reading ${fileName}: ${err.message}`));
                        });
                    });
                }
            });

            zipfile.on('end', () => {
                resolve({ entries });
            });

            zipfile.on('error', (err) => {
                reject(new Error(`ZIP file error: ${err.message}`));
            });
        });
    });
}

/**
 * Write extracted files to disk
 */
async function writeExtractedFiles(entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>, extractDir: string): Promise<void> {
    // Create base extraction directory
    if (!fs.existsSync(extractDir)) {
        fs.mkdirSync(extractDir, { recursive: true });
    }

    for (const entry of entries) {
        const fullPath = path.join(extractDir, entry.fileName);

        if (entry.isDirectory) {
            // Create directory
            if (!fs.existsSync(fullPath)) {
                fs.mkdirSync(fullPath, { recursive: true });
            }
        } else {
            // Create parent directory if it doesn't exist
            const parentDir = path.dirname(fullPath);
            if (!fs.existsSync(parentDir)) {
                fs.mkdirSync(parentDir, { recursive: true });
            }

            // Write file
            fs.writeFileSync(fullPath, entry.content);
            console.log(`  üíæ Wrote: ${entry.fileName}`);
        }
    }
}

/**
 * Parse EPUB metadata from extracted content
 */
async function parseEpubMetadata(entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>): Promise<{
    opfPath: string;
    title?: string;
    creator?: string;
    language?: string;
    identifier?: string;
    spine: Array<{ id: string; href: string; }>;
    manifest: Map<string, { href: string; mediaType: string; }>;
}> {
    // Step 1: Parse container.xml to find OPF location
    const containerEntry = entries.find(entry => entry.fileName === 'META-INF/container.xml');
    if (!containerEntry) {
        throw new Error('META-INF/container.xml not found in EPUB');
    }

    const containerXml = containerEntry.content.toString('utf-8');
    const containerData = await xml2js.parseStringPromise(containerXml);

    const rootfiles = containerData?.container?.rootfiles?.[0]?.rootfile;
    if (!rootfiles || !Array.isArray(rootfiles) || rootfiles.length === 0) {
        throw new Error('No rootfile found in container.xml');
    }

    const opfPath = rootfiles[0].$['full-path'];
    console.log(`  üìç Container points to OPF: ${opfPath}`);

    // Step 2: Parse the OPF file
    const opfEntry = entries.find(entry => entry.fileName === opfPath);
    if (!opfEntry) {
        throw new Error(`OPF file not found: ${opfPath}`);
    }

    const opfXml = opfEntry.content.toString('utf-8');
    const opfData = await xml2js.parseStringPromise(opfXml);

    // Extract metadata
    const metadata = opfData?.package?.metadata?.[0];
    const title = metadata?.['dc:title']?.[0]?._ || metadata?.['dc:title']?.[0];
    const creator = metadata?.['dc:creator']?.[0]?._ || metadata?.['dc:creator']?.[0];
    const language = metadata?.['dc:language']?.[0]?._ || metadata?.['dc:language']?.[0];
    const identifier = metadata?.['dc:identifier']?.[0]?._ || metadata?.['dc:identifier']?.[0];

    // Extract manifest (list of all files with their metadata)
    const manifest = new Map<string, { href: string; mediaType: string; }>();
    const manifestItems = opfData?.package?.manifest?.[0]?.item || [];
    for (const item of manifestItems) {
        const id = item.$.id;
        const href = item.$.href;
        const mediaType = item.$['media-type'];
        manifest.set(id, { href, mediaType });
    }

    // Extract spine (reading order)
    const spine: Array<{ id: string; href: string; }> = [];
    const spineItems = opfData?.package?.spine?.[0]?.itemref || [];
    for (const itemref of spineItems) {
        const idref = itemref.$.idref;
        const manifestItem = manifest.get(idref);
        if (manifestItem) {
            spine.push({ id: idref, href: manifestItem.href });
        }
    }

    console.log(`  üìö Found ${manifest.size} manifest items`);
    console.log(`  üìñ Reading order: ${spine.length} chapters`);

    return {
        opfPath,
        title,
        creator,
        language,
        identifier,
        spine,
        manifest
    };
}

/**
 * Content classification types
 */
interface ContentClassification {
    frontMatter: Array<{ id: string; href: string; title?: string; }>;
    prologue?: { id: string; href: string; title?: string; };
    chapters: Array<{ id: string; href: string; title?: string; chapterNumber: number; }>;
    epilogue?: { id: string; href: string; title?: string; };
    backMatter: Array<{ id: string; href: string; title?: string; }>;
}

/**
 * Classify EPUB content based on structure and order
 */
async function classifyEpubContent(
    spine: Array<{ id: string; href: string; }>,
    entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>
): Promise<ContentClassification> {
    const classification: ContentClassification = {
        frontMatter: [],
        chapters: [],
        backMatter: []
    };

    // Extract title and analyze content patterns
    const analyzeContent = (content: string): {
        title?: string;
        hasSubstantialText: boolean;
        patterns: string[];
        wordCount: number;
        calibreChapterNumber?: number;
    } => {
        // Extract calibre chapter information from h1.chapn elements (do this first)
        const calibreChapterMatch = content.match(/<h1[^>]*class="chapn"[^>]*>(.*?)<\/h1>/s) ||
            content.match(/<h1[^>]*class="chap_n"[^>]*>(.*?)<\/h1>/s);
        let calibreChapterNumber: number | undefined;
        if (calibreChapterMatch) {
            // Extract just the number from the h1 content, ignoring HTML tags
            const h1Text = calibreChapterMatch[1].replace(/<[^>]*>/g, '').trim();
            // Handle both plain numbers (31) and bracketed numbers ([1])
            const numberMatch = h1Text.match(/^(\d+)$/) || h1Text.match(/^\[(\d+)\]$/);
            calibreChapterNumber = numberMatch ? parseInt(numberMatch[1]) : undefined;
        }

        // Extract title from various sources, but be smart about it
        const h1Match = content.match(/<h1[^>]*>(.*?)<\/h1>/is);
        const h1Text = h1Match ? h1Match[1].replace(/<[^>]*>/g, '').trim() : null;

        const titleMatches = [
            content.match(/<title[^>]*>([^<]+)<\/title>/i),
            h1Text ? [null, h1Text] : null, // Convert to match format
            content.match(/<h2[^>]*>([^<]+)<\/h2>/i),
            content.match(/<h3[^>]*>([^<]+)<\/h3>/i)
        ].filter(Boolean); // Remove null entries

        // Analyze patterns first to determine content type
        const textContent = content
            .replace(/<[^>]*>/g, ' ') // Remove HTML tags
            .replace(/\s+/g, ' ') // Normalize whitespace
            .trim();

        const lowerContent = content.toLowerCase();
        const lowerText = textContent.toLowerCase();

        // Check for structural content types
        const isEpilogue = lowerText.match(/^(epilogue|√©pilogue|conclusion|postface)/) ||
            (lowerContent.includes('<h1') && lowerContent.includes('√©pilogue'));
        const isPrologue = lowerText.match(/^(prologue|pr√©face|avant-propos|introduction)/) ||
            (lowerContent.includes('<h1') && lowerContent.includes('prologue'));

        let title: string | undefined;

        // Priority 1: If we have a calibre chapter number, use it directly as the title
        if (calibreChapterNumber !== undefined) {
            title = calibreChapterNumber.toString();
        }
        // Priority 2: For structural content (epilogue/prologue), use generic titles
        else if (isEpilogue) {
            title = 'Epilogue';
        } else if (isPrologue) {
            title = 'Prologue';
        }
        // Priority 3: Extract title from content only as last resort
        else {
            for (const match of titleMatches) {
                if (match?.[1]) {
                    const candidateTitle = match[1].trim().replace(/&[^;]+;/g, ''); // Basic HTML entity cleanup

                    // Skip titles that look like dates or preliminary content for main chapters
                    const isDateLike = /^\w+\s+\d{1,2}\s+\w+\s+\d{4}$/.test(candidateTitle); // "Friday 22 November 2013"
                    const isTimeLike = /^\w+\s+mois\s+plus\s+tard$/.test(candidateTitle); // "Sept mois plus tard"

                    // Accept the first reasonable title we find
                    if (!isDateLike && !isTimeLike) {
                        title = candidateTitle;
                        break;
                    }
                }
            }
        }

        // Clean text content for analysis (reuse variables from above)
        const wordCount = textContent.split(/\s+/).filter(word => word.length > 0).length;
        const hasSubstantialText = wordCount > 50; // More than 50 words indicates substantial content

        // Detect patterns in content and structure
        const patterns: string[] = [];

        // Structural patterns
        if (lowerContent.includes('pagetitre') || lowerContent.includes('auteur_ident')) patterns.push('title-page');
        if (lowerContent.includes('copyright') || lowerContent.includes('pagecopyright')) patterns.push('copyright');
        if (lowerContent.includes('exergues') || lowerContent.includes('epigraph')) patterns.push('epigraph');
        if (lowerContent.includes('toc') || lowerContent.includes('table') || lowerText.includes('sommaire')) patterns.push('toc');
        if (lowerContent.includes('dedication') || lowerText.includes('d√©dicace')) patterns.push('dedication');

        // Content-based patterns
        if (lowerText.match(/^(prologue|pr√©face|avant-propos|introduction)/)) patterns.push('prologue');
        if (lowerText.match(/^(epilogue|√©pilogue|conclusion|postface)/)) patterns.push('epilogue');
        if (lowerText.includes('chapitre') || lowerText.includes('chapter')) patterns.push('chapter-marker');

        // Calibre-specific patterns
        if (content.includes('class="chapn"')) patterns.push('calibre-chapter-marker');
        if (calibreChapterNumber !== undefined) patterns.push('calibre-numbered-chapter');

        // Structural epilogue/prologue headers (title-only pages)
        if (lowerContent.includes('<h1') && lowerContent.includes('√©pilogue')) patterns.push('epilogue-header');
        if (lowerContent.includes('<h1') && lowerContent.includes('prologue')) patterns.push('prologue-header');

        // Image-heavy content (likely front matter)
        const imageCount = (content.match(/<img[^>]*>/g) || []).length;
        if (imageCount > 0 && wordCount < 20) patterns.push('image-heavy');

        return { title, hasSubstantialText, patterns, wordCount, calibreChapterNumber };
    };

    // Analyze each spine item
    const spineWithAnalysis = await Promise.all(spine.map(async (spineItem, index) => {
        const entry = entries.find(e => e.fileName.includes(spineItem.href) && !e.isDirectory);
        let analysis = { title: undefined as string | undefined, hasSubstantialText: false, patterns: [] as string[], wordCount: 0, calibreChapterNumber: undefined as number | undefined };

        if (entry) {
            try {
                const content = entry.content.toString('utf-8');
                const contentAnalysis = analyzeContent(content);
                analysis = {
                    title: contentAnalysis.title,
                    hasSubstantialText: contentAnalysis.hasSubstantialText,
                    patterns: contentAnalysis.patterns,
                    wordCount: contentAnalysis.wordCount,
                    calibreChapterNumber: contentAnalysis.calibreChapterNumber
                };
            } catch (error) {
                console.warn(`Warning: Could not read content from ${spineItem.href}`);
            }
        }

        return { ...spineItem, analysis, originalIndex: index };
    }));

    // Find the transition points based on structure and content
    const totalItems = spineWithAnalysis.length;
    let mainContentStart = 0;
    let mainContentEnd = totalItems - 1;

    // Identify front matter boundary
    for (let i = 0; i < Math.min(10, totalItems); i++) {
        const item = spineWithAnalysis[i];
        const { patterns, hasSubstantialText, wordCount } = item.analysis;

        // If this item has substantial content and no front matter patterns, main content starts here
        if (hasSubstantialText &&
            wordCount > 200 && // Significant word count
            !patterns.some(p => ['title-page', 'copyright', 'epigraph', 'toc', 'dedication', 'image-heavy'].includes(p))) {
            mainContentStart = i;
            break;
        }

        // Special handling for items with prologue patterns
        if (patterns.includes('prologue') || patterns.includes('prologue-header')) {
            mainContentStart = i;
            break;
        }
    }

    // Identify back matter boundary (work backwards)
    for (let i = totalItems - 1; i >= Math.max(totalItems - 10, mainContentStart); i--) {
        const item = spineWithAnalysis[i];
        const { patterns, hasSubstantialText, wordCount } = item.analysis;

        // If this item has substantial content and no back matter patterns, main content ends here
        if (hasSubstantialText &&
            wordCount > 200 &&
            !patterns.some(p => ['epilogue', 'acknowledgment', 'bibliography', 'index'].includes(p))) {
            mainContentEnd = i;
            break;
        }

        // Special handling for items with epilogue patterns
        if (patterns.includes('epilogue')) {
            mainContentEnd = i;
            break;
        }
    }

    // Classify front matter
    for (let i = 0; i < mainContentStart; i++) {
        const item = spineWithAnalysis[i];
        classification.frontMatter.push({
            id: item.id,
            href: item.href,
            title: item.analysis.title
        });
    }

    // Classify back matter
    for (let i = mainContentEnd + 1; i < totalItems; i++) {
        const item = spineWithAnalysis[i];
        classification.backMatter.push({
            id: item.id,
            href: item.href,
            title: item.analysis.title
        });
    }

    // Analyze main content section for prologue, chapters, and epilogue
    const mainContentItems = spineWithAnalysis.slice(mainContentStart, mainContentEnd + 1);

    // Check for prologue in main content (can be header + content or just content)
    // Look for prologue header pattern first
    let prologueFound = false;
    for (let i = 0; i < Math.min(3, mainContentItems.length); i++) {
        if (mainContentItems[i]?.analysis.patterns.includes('prologue-header')) {
            // Found prologue header, check if next item exists and has substantial content
            if (i + 1 < mainContentItems.length &&
                mainContentItems[i + 1].analysis.hasSubstantialText &&
                mainContentItems[i + 1].analysis.wordCount > 100) {
                classification.prologue = {
                    id: mainContentItems[i + 1].id,
                    href: mainContentItems[i + 1].href,
                    title: 'Prologue' // Override title for prologue content
                };
                // Remove both header and content from main content
                mainContentItems.splice(i, 2);
            } else {
                // Check if this header item itself has substantial content
                if (mainContentItems[i].analysis.hasSubstantialText &&
                    mainContentItems[i].analysis.wordCount > 100) {
                    // The header contains the content too
                    classification.prologue = {
                        id: mainContentItems[i].id,
                        href: mainContentItems[i].href,
                        title: 'Prologue' // Override title for prologue content
                    };
                    mainContentItems.splice(i, 1);
                } else {
                    // Just the header with no substantial content, skip it
                    continue;
                }
            }
            prologueFound = true;
            break;
        }
    }

    // If no prologue header found, check for direct prologue patterns
    if (!prologueFound) {
        const firstMainItem = mainContentItems[0];
        if (firstMainItem?.analysis.patterns.includes('prologue')) {
            classification.prologue = {
                id: firstMainItem.id,
                href: firstMainItem.href,
                title: firstMainItem.analysis.title || 'Prologue'
            };
            mainContentItems.shift(); // Remove from main content
        }
    }

    // Check for epilogue in main content (can be header + content or just content)
    // Look for epilogue header pattern first
    for (let i = mainContentItems.length - 3; i < mainContentItems.length; i++) {
        if (i >= 0 && mainContentItems[i]?.analysis.patterns.includes('epilogue-header')) {
            // Found epilogue header, check if next item exists and treat it as epilogue content
            if (i + 1 < mainContentItems.length) {
                classification.epilogue = {
                    id: mainContentItems[i + 1].id,
                    href: mainContentItems[i + 1].href,
                    title: 'Epilogue' // Override title for epilogue content
                };
                // Remove both header and content from main content
                mainContentItems.splice(i, 2);
            } else {
                // Just the header, treat it as epilogue
                classification.epilogue = {
                    id: mainContentItems[i].id,
                    href: mainContentItems[i].href,
                    title: 'Epilogue' // Override title for epilogue header
                };
                mainContentItems.splice(i, 1);
            }
            break;
        }
    }

    // If no epilogue header found, check for direct epilogue patterns
    if (!classification.epilogue) {
        const lastMainItem = mainContentItems[mainContentItems.length - 1];
        if (lastMainItem?.analysis.patterns.includes('epilogue')) {
            classification.epilogue = {
                id: lastMainItem.id,
                href: lastMainItem.href,
                title: lastMainItem.analysis.title
            };
            mainContentItems.pop(); // Remove from main content
        }
    }

    // Remaining items are chapters - handle calibre numbering and content pairing
    const chapterItems: Array<{
        id: string;
        href: string;
        title?: string;
        chapterNumber: number;
    }> = [];

    // Build a map of calibre chapter numbers to items
    const calibreChapterMap = new Map<number, typeof mainContentItems[0]>();
    const unNumberedItems: typeof mainContentItems = [];

    for (const item of mainContentItems) {
        if (item.analysis.calibreChapterNumber !== undefined) {
            calibreChapterMap.set(item.analysis.calibreChapterNumber, item);
        } else {
            unNumberedItems.push(item);
        }
    }

    // Process calibre-numbered chapters
    const sortedCalibreNumbers = Array.from(calibreChapterMap.keys()).sort((a, b) => a - b);

    for (let i = 0; i < sortedCalibreNumbers.length; i++) {
        const calibreNum = sortedCalibreNumbers[i];
        const markerItem = calibreChapterMap.get(calibreNum)!;

        // Check if this is just a chapter marker (minimal content) or actual chapter content
        const isJustMarker = markerItem.analysis.wordCount < 200 &&
            markerItem.analysis.patterns.includes('calibre-chapter-marker');

        if (isJustMarker) {
            // This is a chapter marker, look for the next unnumbered item as the content
            const nextContentItem = unNumberedItems.find(item =>
                item.originalIndex > markerItem.originalIndex &&
                item.analysis.hasSubstantialText &&
                item.analysis.wordCount > 200
            );

            if (nextContentItem) {
                // Use the content item but with the calibre chapter number and title from marker
                chapterItems.push({
                    id: nextContentItem.id,
                    href: nextContentItem.href,
                    title: markerItem.analysis.title || `[${calibreNum}]`, // Use marker title, fallback to [X]
                    chapterNumber: calibreNum
                });

                // Remove the content item from unnumbered items to avoid double processing
                const contentIndex = unNumberedItems.indexOf(nextContentItem);
                if (contentIndex > -1) {
                    unNumberedItems.splice(contentIndex, 1);
                }
            } else {
                // No content found for this chapter marker - check if marker itself has substantial content
                if (markerItem.analysis.hasSubstantialText && markerItem.analysis.wordCount > 100) {
                    // Only include if the marker itself contains substantial content
                    chapterItems.push({
                        id: markerItem.id,
                        href: markerItem.href,
                        title: markerItem.analysis.title || `[${calibreNum}]`, // Use marker title, fallback to [X]
                        chapterNumber: calibreNum
                    });
                }
                // If marker has no substantial content, skip this chapter entirely
            }
        } else {
            // This item has both the marker and substantial content
            chapterItems.push({
                id: markerItem.id,
                href: markerItem.href,
                title: markerItem.analysis.title,
                chapterNumber: calibreNum
            });
        }
    }

    // Handle any remaining unnumbered items as additional chapters
    let nextChapterNumber = sortedCalibreNumbers.length > 0 ? Math.max(...sortedCalibreNumbers) + 1 : 1;
    for (const item of unNumberedItems) {
        if (item.analysis.hasSubstantialText && item.analysis.wordCount > 200) {
            chapterItems.push({
                id: item.id,
                href: item.href,
                title: item.analysis.title,
                chapterNumber: nextChapterNumber++
            });
        }
    }

    // Sort chapters by their calibre chapter number
    chapterItems.sort((a, b) => a.chapterNumber - b.chapterNumber);

    // Final filter: Remove any chapters that will result in empty content
    // by checking actual content from entries for each chapter
    const filteredChapterItems = await Promise.all(
        chapterItems.map(async (chapterItem) => {
            const entry = entries.find(e => e.fileName.includes(chapterItem.href) && !e.isDirectory);
            if (!entry) return null;

            try {
                const content = entry.content.toString('utf-8');
                const textContent = content
                    .replace(/<[^>]*>/g, ' ') // Remove HTML tags
                    .replace(/\s+/g, ' ') // Normalize whitespace
                    .trim();

                const wordCount = textContent.split(/\s+/).filter(word => word.length > 0).length;

                // Only include chapters with substantial content (more than just a chapter marker)
                if (wordCount > 20) {  // Must have more than just a chapter marker
                    return chapterItem;
                }

                return null;
            } catch (error) {
                console.warn(`Warning: Could not verify content for chapter ${chapterItem.chapterNumber}`);
                return chapterItem; // Keep on error to be safe
            }
        })
    );

    // Filter out null values and renumber chapters sequentially
    const validChapterItems = filteredChapterItems.filter(item => item !== null) as typeof chapterItems;

    // Renumber chapters to be sequential starting from 1
    const finalChapterItems = validChapterItems.map((item, index) => ({
        ...item,
        chapterNumber: index + 1
    }));

    classification.chapters = finalChapterItems;

    return classification;
}

/**
 * Generate Obsidian-compatible output from EPUB
 */
async function generateObsidianOutput(
    entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>,
    metadata: {
        title?: string;
        creator?: string;
        language?: string;
        identifier?: string;
        opfPath: string;
        spine: Array<{ id: string; href: string; }>;
        manifest: Map<string, { href: string; mediaType: string; }>;
    },
    outputPath: string,
    contentClassification: ContentClassification
): Promise<void> {
    // Sanitize title for folder name
    const sanitizedTitle = sanitizeFileName(metadata.title || 'Unknown Title');
    const bookDir = path.join(outputPath, sanitizedTitle);

    // Create output directory
    if (!fs.existsSync(outputPath)) {
        fs.mkdirSync(outputPath, { recursive: true });
    }
    if (!fs.existsSync(bookDir)) {
        fs.mkdirSync(bookDir, { recursive: true });
    }

    console.log(`üìÅ Creating book directory: ${bookDir}`);

    // Extract cover image
    const coverFileName = await extractCoverImage(entries, metadata, bookDir);

    // Generate main book note
    await generateBookNote(metadata, bookDir, coverFileName, contentClassification);

    // Process and generate chapter content
    await processChapterContent(entries, contentClassification, bookDir, metadata.title || 'Unknown Title');

    console.log(`‚úÖ Obsidian output generated successfully!`);
}

/**
 * Sanitize filename for cross-platform compatibility
 */
function sanitizeFileName(name: string): string {
    return name
        .replace(/[<>:"/\\|?*]/g, '-')  // Replace invalid characters
        .replace(/\s+/g, ' ')           // Normalize whitespace
        .trim()                         // Remove leading/trailing spaces
        .replace(/\.$/, '')             // Remove trailing period
        .substring(0, 255);             // Limit length
}

/**
 * Extract cover image to the book directory
 */
async function extractCoverImage(
    entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>,
    metadata: {
        title?: string;
        manifest: Map<string, { href: string; mediaType: string; }>;
    },
    bookDir: string
): Promise<string | null> {
    // Look for cover image in manifest
    let coverImageEntry: { fileName: string; content: Buffer; } | undefined;

    // Try to find cover by common names
    const possibleCoverNames = ['cover.jpg', 'cover.jpeg', 'cover.png', 'cover.gif'];

    for (const coverName of possibleCoverNames) {
        coverImageEntry = entries.find(entry =>
            entry.fileName.toLowerCase().includes(coverName.toLowerCase()) && !entry.isDirectory
        );
        if (coverImageEntry) break;
    }

    // If not found by name, look for images in root or images folder
    if (!coverImageEntry) {
        coverImageEntry = entries.find(entry =>
            !entry.isDirectory &&
            (entry.fileName.endsWith('.jpg') ||
                entry.fileName.endsWith('.jpeg') ||
                entry.fileName.endsWith('.png') ||
                entry.fileName.endsWith('.gif')) &&
            (entry.fileName.split('/').length <= 2) // Root or one level deep
        );
    }

    if (coverImageEntry) {
        const originalExt = path.extname(coverImageEntry.fileName);
        const sanitizedTitle = sanitizeFileName(metadata.title || 'Unknown Title');
        const coverFileName = `${sanitizedTitle}${originalExt}`;
        const coverPath = path.join(bookDir, coverFileName);

        fs.writeFileSync(coverPath, coverImageEntry.content);
        console.log(`üñºÔ∏è Extracted cover: ${coverFileName}`);
        return coverFileName;
    } else {
        console.log(`‚ö†Ô∏è No cover image found`);
        return null;
    }
}

/**
 * Generate the main book note in Obsidian format
 */
async function generateBookNote(
    metadata: {
        title?: string;
        creator?: string;
        language?: string;
        identifier?: string;
        spine: Array<{ id: string; href: string; }>;
    },
    bookDir: string,
    coverFileName?: string | null,
    contentClassification?: ContentClassification
): Promise<void> {
    const sanitizedTitle = sanitizeFileName(metadata.title || 'Unknown Title');
    const noteFileName = `${sanitizedTitle}.md`;
    const notePath = path.join(bookDir, noteFileName);

    // Generate Obsidian-formatted metadata
    let obsidianNote = `---
title: "${metadata.title || 'Unknown Title'}"
author: "${metadata.creator || 'Unknown Author'}"
language: "${metadata.language || 'Unknown'}"
identifier: "${metadata.identifier || 'Unknown'}"
type: book
source: epub
chapters: ${contentClassification?.chapters.length || metadata.spine.length}
imported: ${new Date().toISOString().split('T')[0]}${coverFileName ? `\ncover: "[[${coverFileName}]]"` : ''}
---

# ${metadata.title || 'Unknown Title'}
`;

    // Add content structure if available
    if (contentClassification) {
        // Add chapters list with prologue and epilogue included
        obsidianNote += `\n## Table of Contents\n\n`;

        // Add prologue if exists
        if (contentClassification.prologue) {
            const prologueTitle = contentClassification.prologue.title || 'Prologue';
            const prologueFileName = `${sanitizedTitle} - ${sanitizeFileName(prologueTitle)}`;
            obsidianNote += `**Prologue**: [[${prologueFileName}]]\n`;
        }

        // Add all chapters
        contentClassification.chapters.forEach((chapter, index) => {
            const chapterNumber = chapter.chapterNumber || index + 1;
            const chapterFileName = `${sanitizedTitle} - Chapter ${chapterNumber}`;
            obsidianNote += `${chapterNumber}. [[${chapterFileName}]]\n`;
        });

        // Add epilogue if exists
        if (contentClassification.epilogue) {
            const epilogueTitle = contentClassification.epilogue.title || 'Epilogue';
            const epilogueFileName = `${sanitizedTitle} - ${sanitizeFileName(epilogueTitle)}`;
            obsidianNote += `**Epilogue**: [[${epilogueFileName}]]\n`;
        }
    }

    fs.writeFileSync(notePath, obsidianNote);
    console.log(`üìù Generated book note: ${noteFileName}`);
}

/**
 * Process chapter content and convert to Obsidian format using calibre markup
 */
async function processChapterContent(
    entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>,
    contentClassification: ContentClassification,
    bookDir: string,
    bookTitle: string
): Promise<void> {
    console.log(`üìö Processing ${contentClassification.chapters.length} chapters...`);

    // Process prologue if exists
    if (contentClassification.prologue) {
        await processContentFile(
            entries,
            contentClassification.prologue.href,
            contentClassification.prologue.title || 'Prologue',
            bookDir,
            'prologue',
            undefined,
            bookTitle
        );
    }

    // Process each chapter
    for (const chapter of contentClassification.chapters) {
        // Always use the sequential chapter number as title to ensure bijection
        const chapterTitle = chapter.chapterNumber.toString();

        await processContentFile(
            entries,
            chapter.href,
            chapterTitle,
            bookDir,
            'chapter',
            chapter.chapterNumber,
            bookTitle
        );
    }

    // Process epilogue if exists
    if (contentClassification.epilogue) {
        await processContentFile(
            entries,
            contentClassification.epilogue.href,
            contentClassification.epilogue.title || 'Epilogue',
            bookDir,
            'epilogue',
            undefined,
            bookTitle
        );
    }

    console.log(`‚úÖ Processed all chapter content`);
}

/**
 * Process a single content file and convert to Obsidian Markdown
 */
async function processContentFile(
    entries: Array<{ fileName: string; content: Buffer; isDirectory: boolean; }>,
    href: string,
    title: string,
    bookDir: string,
    type: 'prologue' | 'chapter' | 'epilogue',
    chapterNumber?: number,
    bookTitle?: string
): Promise<void> {
    // Find the content entry
    const entry = entries.find(e => e.fileName.includes(href) && !e.isDirectory);
    if (!entry) {
        console.warn(`‚ö†Ô∏è Content file not found: ${href}`);
        return;
    }

    try {
        const content = entry.content.toString('utf-8');
        const markdownContent = convertCalibreToMarkdown(content, title, type, chapterNumber, bookTitle);

        // Generate proper filename based on type
        let noteFileName: string;
        const sanitizedBookTitle = sanitizeFileName(bookTitle || 'Book');

        if (type === 'prologue') {
            noteFileName = `${sanitizedBookTitle} - Prologue.md`;
        } else if (type === 'epilogue') {
            noteFileName = `${sanitizedBookTitle} - Epilogue.md`;
        } else if (type === 'chapter' && chapterNumber) {
            noteFileName = `${sanitizedBookTitle} - Chapter ${chapterNumber}.md`;
        } else {
            // Fallback
            const sanitizedTitle = sanitizeFileName(title);
            noteFileName = `${sanitizedTitle}.md`;
        }

        const notePath = path.join(bookDir, noteFileName);

        fs.writeFileSync(notePath, markdownContent);
        console.log(`üìÑ Generated ${type}: ${noteFileName}`);
    } catch (error) {
        console.error(`‚ùå Error processing ${href}:`, error);
    }
}

/**
 * Convert Calibre XHTML content to Obsidian Markdown using calibre markup patterns
 */
function convertCalibreToMarkdown(
    content: string,
    title: string,
    type: 'prologue' | 'chapter' | 'epilogue',
    chapterNumber?: number,
    bookTitle?: string
): string {
    let markdown = '';

    // Add frontmatter
    markdown += `---\n`;
    markdown += `title: "${title}"\n`;
    markdown += `type: ${type}\n`;
    if (chapterNumber) {
        markdown += `chapter: ${chapterNumber}\n`;
    }
    if (bookTitle) {
        markdown += `book: "${bookTitle}"\n`;
    }
    markdown += `source: epub\n`;
    markdown += `---\n\n`;

    // Add title
    markdown += `# ${title}\n\n`;

    // Extract main content by removing HTML tags but preserving structure
    let textContent = content;

    // Remove HTML structure but preserve calibre hints
    textContent = textContent
        .replace(/<\?xml[^>]*\?>/g, '') // Remove XML declaration
        .replace(/<html[^>]*>/g, '') // Remove html tag
        .replace(/<\/html>/g, '') // Remove closing html tag
        .replace(/<head>.*?<\/head>/gs, '') // Remove head section
        .replace(/<body[^>]*>/g, '') // Remove body tag
        .replace(/<\/body>/g, '') // Remove closing body tag
        .replace(/<div[^>]*class="exergues"[^>]*>/g, '') // Remove chapter container
        .replace(/<div[^>]*class="pagetitre"[^>]*><\/div>/g, '') // Remove page title divs
        // Handle chapter number and title structure specially
        .replace(/<h1[^>]*class="chapn"[^>]*>(.*?)<\/h1>/gs, '') // Remove chapter number headers (redundant with title)
        .replace(/<h1[^>]*class="chap_n"[^>]*>(.*?)<\/h1>/gs, '') // Remove chapter number headers (Pandemia style, redundant with title)
        .replace(/<h1[^>]*class="chaptit"[^>]*>(.*?)<\/h1>/gs, (match, content) => {
            // Extract the chapter subtitle (like date)
            const cleanContent = content.replace(/<[^>]*>/g, '').trim();
            return `**${cleanContent}**\n\n`; // Make chapter subtitle bold
        })
        .replace(/<h2[^>]*class="int_niv"[^>]*>(.*?)<\/h2>/gs, (match, content) => {
            // Extract the chapter subtitle (Pandemia style - like date)
            const cleanContent = content.replace(/<[^>]*>/g, '').trim();
            return `**${cleanContent}**\n\n`; // Make chapter subtitle bold
        })
        .replace(/<h1[^>]*class="prestit"[^>]*>(.*?)<\/h1>/gs, (match, content) => {
            // Extract the prologue subtitle (like date)
            const cleanContent = content.replace(/<[^>]*>/g, '').trim();
            return `**${cleanContent}**\n\n`; // Make prologue subtitle bold
        })
        .replace(/<h1[^>]*class="pre_tit"[^>]*>(.*?)<\/h1>/gs, '') // Remove prologue title headers (Pandemia style, redundant with title)
        .replace(/<div[^>]*class="dev"[^>]*>/g, '') // Remove dev containers
        .replace(/<\/div>/g, ''); // Remove closing divs

    // Convert calibre text classes to markdown
    textContent = textContent
        // Convert paragraph with first letter styling
        .replace(/<p class="txt_courant_ssalinea"><span class="let">(.*?)<\/span>(.*?)<\/p>/gs, '**$1**$2\n\n')
        // Convert regular paragraphs (various patterns) - use non-greedy matching with dot-all
        .replace(/<p class="txt_courant_[^"]*">(.*?)<\/p>/gs, '$1\n\n')
        .replace(/<p class="txtcourant[^"]*">(.*?)<\/p>/gs, '$1\n\n')
        .replace(/<p class="txtcourantjustif">(.*?)<\/p>/gs, '$1\n\n')
        // Convert justified paragraphs
        .replace(/<p class="txt_courant_justif">(.*?)<\/p>/gs, '$1\n\n')
        // Convert generic paragraphs - make this more greedy to catch all paragraphs
        .replace(/<p[^>]*>(.*?)<\/p>/gs, '$1\n\n')
        // Convert italic text
        .replace(/<i class="calibre2">(.*?)<\/i>/gs, '*$1*')
        // Remove page anchors (no longer needed per requirements)
        .replace(/<a id="page_(\d+)" class="calibre[^"]*"><\/a>/g, '')
        .replace(/<a id="page_(\d+)" class="calibre\d+"><\/a>/g, '');

    // Handle special content blocks like letters
    textContent = textContent
        .replace(/<div class="lettre">/g, '\n> **Letter/Email:**\n> ')
        .replace(/<\/div>/g, '\n\n');

    // Clean up remaining HTML tags
    textContent = textContent
        .replace(/<[^>]*>/g, '') // Remove any remaining HTML tags
        .replace(/&[^;]+;/g, '') // Remove HTML entities (basic cleanup)
        .replace(/\n\s*\n\s*\n/g, '\n\n') // Normalize multiple newlines
        .replace(/^[ \t]+/gm, '') // Remove leading whitespace/indentation from lines with content (but preserve blank lines)
        .replace(/(\d+)([A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û][a-z√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]+\s+\d{4})([A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û])/g, '$1\n\n$2\n\n$3') // Fix date formatting: "32Novembre 2010La" -> "32\n\nNovembre 2010\n\nLa"
        .trim();

    markdown += textContent;

    return markdown;
}

// Parse command line arguments and execute
export function runCLI(): void {
    program.parse();
}

if (require.main === module) {
    runCLI();
}